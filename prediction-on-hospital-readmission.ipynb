{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Prediction on Diabetes Patient's Hospital Readmission\n\n![](https://www.docwirenews.com/wp-content/uploads/2019/05/readmissions.jpg)\n\nProblem Statement and Objective\nA hospital readmission is when a patient who is discharged from the hospital, gets re-admitted again within a certain period of time. Hospital readmission rates for certain conditions are now considered an indicator of hospital quality, and also affect the cost of care adversely. For this reason, Centers for Medicare & Medicaid Services established the Hospital Readmissions Reduction Program which aims to improve quality of care for patients and reduce health care spending by applying payment penalties to hospitals that have more than expected readmission rates for certain conditions. Although diabetes is not yet included in the penalty measures, the program is regularly adding new disease conditions to the list, now totaling 6 for FY2018. In 2011, American hospitals spent over $41 billion on diabetic patients who got readmitted within 30 days of discharge. Being able to determine factors that lead to higher readmission in such patients, and correspondingly being able to predict which patients will get readmitted can help hospitals save millions of dollars while improving quality of care. So, with that background in mind, we used a medical claims dataset (description below), to answer these questions:\n\n1. What factors are the strongest predictors of hospital readmission in diabetic patients?\n2. How well can we predict hospital readmission in this dataset with limited features?","metadata":{}},{"cell_type":"markdown","source":"# Data Set Description\n\n\n**VARIABLE NAMES**: DESCRIPTION\n* **Encounter ID**\tUnique identifier of an encounter\n* **Patient number**\tUnique identifier of a patient\n* **Race**\tValues: Caucasian, Asian, African American, Hispanic, and other\n* **Gender**\tValues: male, female, and unknown/invalid\n* **Age**\tGrouped in 10-year intervals: 0, 10), 10, 20), …, 90, 100)\n* **Weight**\tWeight in pounds\n* **Admission type**\tInteger identifier corresponding to 9 distinct values, for example, emergency, urgent, elective, newborn, and not available\n* **Discharge disposition**\tInteger identifier corresponding to 29 distinct values, for example, discharged to home, expired, and not available\n* **Admission source**\tInteger identifier corresponding to 21 distinct values, for example, physician referral, emergency room, and transfer from a hospital\n* **Time in hospital**\tInteger number of days between admission and discharge\n* **Payer code**\tInteger identifier corresponding to 23 distinct values, for example, Blue Cross/Blue Shield, Medicare, and self-pay Medical\n* **Medical specialty**\tInteger identifier of a specialty of the admitting physician, corresponding to 84 distinct values, for example, cardiology, internal medicine, family/general practice, and surgeon\n* **Number of lab procedures**\tNumber of lab tests performed during the encounter\n* **Number of procedures** Numeric\tNumber of procedures (other than lab tests) performed during the encounter\n* **Number of medications**\tNumber of distinct generic names administered during the encounter\n* **Number of outpatient visits** Number of outpatient visits of the patient in the year preceding the encounter\n* **Number of emergency visits**\tNumber of emergency visits of the patient in the year preceding the encounter\n* **Number of inpatient visits**\tNumber of inpatient visits of the patient in the year preceding the encounter\n* **Diagnosis 1**\tThe primary diagnosis (coded as first three digits of ICD9); 848 distinct values\n* **Diagnosis 2**\tSecondary diagnosis (coded as first three digits of ICD9); 923 distinct values\n* **Diagnosis 3** Additional secondary diagnosis (coded as first three digits of ICD9); 954 distinct values\n* **Number of diagnoses**\tNumber of diagnoses entered to the system 0%\n* **Glucose serum test result**\tIndicates the range of the result or if the test was not taken. Values: “>200,” “>300,” “normal,” and “none” if not measured\n* **A1c test result**\tIndicates the range of the result or if the test was not taken. Values: “>8” if the result was greater than 8%, “>7” if the result was greater than 7% but less than 8%, “normal” if the result was less than 7%, and “none” if not measured.\n* **Change of medications**\tIndicates if there was a change in diabetic medications (either dosage or generic name). Values: “change” and “no change”\n* **Diabetes medications**\tIndicates if there was any diabetic medication prescribed. Values: “yes” and “no”\n* 24 features for medications\tFor the generic names: **metformin, repaglinide, nateglinide, chlorpropamide, glimepiride, acetohexamide, glipizide, glyburide, tolbutamide, pioglitazone, rosiglitazone, acarbose, miglitol, troglitazone, tolazamide, examide, sitagliptin, insulin, glyburide-metformin, glipizide-metformin, glimepiride- pioglitazone, metformin-rosiglitazone, and metformin- pioglitazone**, the feature indicates whether the drug was prescribed or there was a change in the dosage. Values: “up” if the dosage was increased during the encounter, “down” if the dosage was decreased, “steady” if the dosage did not change, and “no” if the drug was not prescribed\n* **Readmitted**\tDays to inpatient readmission. Values: “<30” if the patient was readmitted in less than 30 days, “>30” if the patient was readmitted in more than 30 days, and “No” for no record of readmission\n\n\n\n\n\n\n\n\n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":true}},{"cell_type":"markdown","source":"# Data Preparation & Exploration ","metadata":{"_uuid":"e8459f4e9e52473b4fe8824724a87798e1946e02"}},{"cell_type":"code","source":"#Loading libraries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"f159da396824602d8ae73fc5cb08f84987ce91f6","trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#loading Dataset\ndf = pd.read_csv(\"../input/diabetic_data.csv\")","metadata":{"_uuid":"d2d61c7050ae4bf21dd0c5e84949ed951483312d","trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#displaying first 10 rows of data\ndf.head(10).T","metadata":{"_uuid":"06c7f80de93a3640a4cdaafc392374cdaf3d4e23","trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#checking shape of the dataset\ndf.shape","metadata":{"_uuid":"3bdb38381d0dfc06aab75ff81c0dc59287ce470f","trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Checking data types of each variable\ndf.dtypes","metadata":{"_uuid":"169448129042f3eba5d3d406bf84f04a11a722d3","trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Checking for missing values in dataset\n#In the dataset missing values are represented as '?' sign\nfor col in df.columns:\n    if df[col].dtype == object:\n         print(col,df[col][df[col] == '?'].count())","metadata":{"_uuid":"fda696aba45c9a0638e4dcf95c292aeba37f0f14","trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# gender was coded differently so we use a custom count for this one            \nprint('gender', df['gender'][df['gender'] == 'Unknown/Invalid'].count())            ","metadata":{"_uuid":"d048d16f638808017b8f95345920cdcec6dc9ff5","trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Dealing with Missing Values\nVariable weight contains approximate 98% of the missing values so there is no significance in filling those missing values so we decided to drop these variables. Variable Payer code and medical specialty contains approximate 40% missing values so we also dropped these variables. Variables race, diag_1, diag_2, diag_3 and gender contains very less missing values as compared to other attributes which we dropped so for these attributes we also decided to drop those where missing values contains.","metadata":{"_uuid":"6e22d1a4d0030454d23ae88722b3030dcbb0b540","trusted":true}},{"cell_type":"code","source":"#dropping columns with large number of missing values\ndf = df.drop(['weight','payer_code','medical_specialty'], axis = 1)","metadata":{"_uuid":"6edaf833116f062e8b729403b2f1bc871fa7c3ff","trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"drop_Idx = set(df[(df['diag_1'] == '?') & (df['diag_2'] == '?') & (df['diag_3'] == '?')].index)\n\ndrop_Idx = drop_Idx.union(set(df['diag_1'][df['diag_1'] == '?'].index))\ndrop_Idx = drop_Idx.union(set(df['diag_2'][df['diag_2'] == '?'].index))\ndrop_Idx = drop_Idx.union(set(df['diag_3'][df['diag_3'] == '?'].index))\ndrop_Idx = drop_Idx.union(set(df['race'][df['race'] == '?'].index))\ndrop_Idx = drop_Idx.union(set(df[df['discharge_disposition_id'] == 11].index))\ndrop_Idx = drop_Idx.union(set(df['gender'][df['gender'] == 'Unknown/Invalid'].index))\nnew_Idx = list(set(df.index) - set(drop_Idx))\ndf = df.iloc[new_Idx]","metadata":{"_uuid":"e7934d84f6119a0d5e524b8d8250a143f6de87bc","trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"variables (drugs named citoglipton and examide), all records have the same value. So essentially these cannot provide any interpretive or discriminatory information for predicting readmission so we decided to drop these two variables\n","metadata":{"_uuid":"930d7a144498a9fabd43d9de775dcd30b76b70c5"}},{"cell_type":"code","source":"df = df.drop(['citoglipton', 'examide'], axis = 1)","metadata":{"_uuid":"c61817d428256fe7dbc6fc4268585a54fc3d5463","trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Checking for missing values in the data\nfor col in df.columns:\n    if df[col].dtype == object:\n         print(col,df[col][df[col] == '?'].count())\n            \nprint('gender', df['gender'][df['gender'] == 'Unknown/Invalid'].count())   ","metadata":{"_uuid":"92231506c0a8f53dddc12d4065db0329ac538a5b","trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"This is highly subjective, and partly depends on a knowledge of health care services, and making sense of the potential relationships between features. There are perhaps thousands of ways to try here. We tried some...\n\n* Service utilization: The data contains variables for number of inpatient (admissions), emergency room visits and outpatient visits for a given patient in the previous one year. These are (crude) measures of how much hospital/clinic services a person has used in the past year. We added these three to create a new variable called service utilization (see figure below). The idea was to see which version gives us better results. Granted, we did not apply any special weighting to the three ingredients of service utilization but we wanted to try something simple at this stage.\n\n","metadata":{}},{"cell_type":"code","source":"df['service_utilization'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"* Number of medication changes: The dataset contains 23 features for 23 drugs (or combos) which indicate for each of these, whether a change in that medication was made or not during the current hospital stay of patient. Medication change for diabetics upon admission has been shown by previous research to be associated with lower readmission rates. We decided to count how many changes were made in total for each patient, and declared that a new feature. The reasoning here was to both simplify the model and possibly discover a relationship with number of changes regardless of which drug was changed.","metadata":{}},{"cell_type":"code","source":"keys = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', 'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\nfor col in keys:\n    colname = str(col) + 'temp'\n    df[colname] = df[col].apply(lambda x: 0 if (x == 'No' or x == 'Steady') else 1)\ndf['numchange'] = 0\nfor col in keys:\n    colname = str(col) + 'temp'\n    df['numchange'] = df['numchange'] + df[colname]\n    del df[colname]\n    \ndf['numchange'].value_counts()  ","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# re-encoding admission type, discharge type and admission source into fewer categories\n\ndf['admission_type_id'] = df['admission_type_id'].replace(2,1)\ndf['admission_type_id'] = df['admission_type_id'].replace(7,1)\ndf['admission_type_id'] = df['admission_type_id'].replace(6,5)\ndf['admission_type_id'] = df['admission_type_id'].replace(8,5)\n\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(6,1)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(8,1)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(9,1)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(13,1)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(3,2)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(4,2)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(5,2)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(14,2)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(22,2)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(23,2)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(24,2)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(12,10)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(15,10)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(16,10)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(17,10)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(25,18)\ndf['discharge_disposition_id'] = df['discharge_disposition_id'].replace(26,18)\n\ndf['admission_source_id'] = df['admission_source_id'].replace(2,1)\ndf['admission_source_id'] = df['admission_source_id'].replace(3,1)\ndf['admission_source_id'] = df['admission_source_id'].replace(5,4)\ndf['admission_source_id'] = df['admission_source_id'].replace(6,4)\ndf['admission_source_id'] = df['admission_source_id'].replace(10,4)\ndf['admission_source_id'] = df['admission_source_id'].replace(22,4)\ndf['admission_source_id'] = df['admission_source_id'].replace(25,4)\ndf['admission_source_id'] = df['admission_source_id'].replace(15,9)\ndf['admission_source_id'] = df['admission_source_id'].replace(17,9)\ndf['admission_source_id'] = df['admission_source_id'].replace(20,9)\ndf['admission_source_id'] = df['admission_source_id'].replace(21,9)\ndf['admission_source_id'] = df['admission_source_id'].replace(13,11)\ndf['admission_source_id'] = df['admission_source_id'].replace(14,11)","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"* Encoding some variables: The original dataset used string values for gender, race, medication change, and each of the 23 drugs used. To better fit those variables into our model, we interpret the variables to numeric binary variables to reflect their nature. For example, we encoded the “ medication change ” feature from “No” (no change) and “Ch” (changed) into 0 and 1. \n","metadata":{}},{"cell_type":"code","source":"df['change'] = df['change'].replace('Ch', 1)\ndf['change'] = df['change'].replace('No', 0)\ndf['gender'] = df['gender'].replace('Male', 1)\ndf['gender'] = df['gender'].replace('Female', 0)\ndf['diabetesMed'] = df['diabetesMed'].replace('Yes', 1)\ndf['diabetesMed'] = df['diabetesMed'].replace('No', 0)\n# keys is the same as before\nfor col in keys:\n    df[col] = df[col].replace('No', 0)\n    df[col] = df[col].replace('Steady', 1)\n    df[col] = df[col].replace('Up', 1)\n    df[col] = df[col].replace('Down', 1)","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"We also reduced both A1C test result and Glucose serum test result into categories of Normal, Abnormal and Not tested.\n","metadata":{}},{"cell_type":"code","source":"df['A1Cresult'] = df['A1Cresult'].replace('>7', 1)\ndf['A1Cresult'] = df['A1Cresult'].replace('>8', 1)\ndf['A1Cresult'] = df['A1Cresult'].replace('Norm', 0)\ndf['A1Cresult'] = df['A1Cresult'].replace('None', -99)\ndf['max_glu_serum'] = df['max_glu_serum'].replace('>200', 1)\ndf['max_glu_serum'] = df['max_glu_serum'].replace('>300', 1)\ndf['max_glu_serum'] = df['max_glu_serum'].replace('Norm', 0)\ndf['max_glu_serum'] = df['max_glu_serum'].replace('None', -99)","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"* Dealing with age: There are different ways to deal with this. The dataset only gives us age as 10 year categories, so we don’t know the exact age of each patient. The previous study on this dataset used age categories as nominal variables, but we wanted to be able to see the effect of increasing age on readmission, even if in a crude way. To do that, we assume that age of the patient on average lies at the midpoint of the age category. For example, if the patient’s age category is 20–30 years, then we assume the age = 25 years. So we converted age categories to midpoints, resulting in a numeric variable:","metadata":{}},{"cell_type":"code","source":"# code age intervals [0-10) - [90-100) from 1-10\nfor i in range(0,10):\n    df['age'] = df['age'].replace('['+str(10*i)+'-'+str(10*(i+1))+')', i+1)\ndf['age'].value_counts()","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Collapsing of Multiple Encounters for same patient Some patients in the dataset had more than one encounter.We could not count them as independent encounters because that bias the results towards those patients who had multiple encounters. Thus we tried multiple techniques to collapse and consolidate multiple encounters for same patient such as:\n\n* Considering more than 2 readmissions across multiple encounters as readmission for collapsed record.\n* Considering average stay at hospital across multiple encounters.\n* Considering the percentage of the medication changes across multiple encounters\n* Considering the total number of the encounters to replace the encounter unique ID\n* Considering the combination of diagnoses across multiple encounters as a list However, taking the features such as “diagnosis”, for instance, we did not find it not meaningful to combine multiple categorical values into an array for building data model. We then considered first encounter and last encounter separately as possible representations of multiple encounters. However, last encounters gave extremely imbalanced data for readmissions (96/4 Readmissions vs No Readmissions) and thus, we decided to use first encounters of patients with multiple encounters. This resulted in dataset being reduced to about 70,000 encounters:","metadata":{}},{"cell_type":"code","source":"df2 = df.drop_duplicates(subset= ['patient_nbr'], keep = 'first')\ndf2.shape\n(70442, 55)","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df.head().T","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"* Encoding the outcome variable: The outcome we are looking at is whether the patient gets readmitted to the hospital within 30 days or not. The variable actually has < 30, > 30 and No Readmission categories. To reduce our problem to a binary classification, we combined the readmission after 30 days and no readmission into a single category:","metadata":{}},{"cell_type":"code","source":"df['readmitted'].value_counts()","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df['readmitted'] = df['readmitted'].replace('>30', 0)\ndf['readmitted'] = df['readmitted'].replace('<30', 1)\ndf['readmitted'] = df['readmitted'].replace('NO', 0)","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"* Categorization of diagnoses: The dataset contained up to three diagnoses for a given patient (primary, secondary and additional). However, each of these had 700–900 unique ICD codes and it is extremely difficult to include them in the model and interpret meaningfully. Therefore, we collapsed these diagnosis codes into 9 disease categories in an almost similar fashion to that done in the original publication using this dataset. These 9 categories include Circulatory, Respiratory, Digestive, Diabetes, Injury, Musculoskeletal, Genitourinary, Neoplasms, and Others. Although we did this for primary, secondary and additional diagnoses, we eventually decided to use only the primary diagnosis in our model. Doing this in python was slightly cumbersome because, well, we are mapping the disease codes to certain category names. Below code should demonstrate this easily.","metadata":{}},{"cell_type":"code","source":"# Creating additional columns for diagnosis# Creati \ndf['level1_diag1'] = df['diag_1']\ndf['level2_diag1'] = df['diag_1']\ndf['level1_diag2'] = df['diag_2']\ndf['level2_diag2'] = df['diag_2']\ndf['level1_diag3'] = df['diag_3']\ndf['level2_diag3'] = df['diag_3']","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df.loc[df['diag_1'].str.contains('V'), ['level1_diag1', 'level2_diag1']] = 0\ndf.loc[df['diag_1'].str.contains('E'), ['level1_diag1', 'level2_diag1']] = 0\ndf.loc[df['diag_2'].str.contains('V'), ['level1_diag2', 'level2_diag2']] = 0\ndf.loc[df['diag_2'].str.contains('E'), ['level1_diag2', 'level2_diag2']] = 0\ndf.loc[df['diag_3'].str.contains('V'), ['level1_diag3', 'level2_diag3']] = 0\ndf.loc[df['diag_3'].str.contains('E'), ['level1_diag3', 'level2_diag3']] = 0\ndf['level1_diag1'] = df['level1_diag1'].replace('?', -1)\ndf['level2_diag1'] = df['level2_diag1'].replace('?', -1)\ndf['level1_diag2'] = df['level1_diag2'].replace('?', -1)\ndf['level2_diag2'] = df['level2_diag2'].replace('?', -1)\ndf['level1_diag3'] = df['level1_diag3'].replace('?', -1)\ndf['level2_diag3'] = df['level2_diag3'].replace('?', -1)","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df['level1_diag1'] = df['level1_diag1'].astype(float)\ndf['level2_diag1'] = df['level2_diag1'].astype(float)\ndf['level1_diag2'] = df['level1_diag2'].astype(float)\ndf['level2_diag2'] = df['level2_diag2'].astype(float)\ndf['level1_diag3'] = df['level1_diag3'].astype(float)\ndf['level2_diag3'] = df['level2_diag3'].astype(float)","metadata":{"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"for index, row in df.iterrows():\n    if (row['level1_diag1'] >= 390 and row['level1_diag1'] < 460) or (np.floor(row['level1_diag1']) == 785):\n        df.loc[index, 'level1_diag1'] = 1\n    elif (row['level1_diag1'] >= 460 and row['level1_diag1'] < 520) or (np.floor(row['level1_diag1']) == 786):\n        df.loc[index, 'level1_diag1'] = 2\n    elif (row['level1_diag1'] >= 520 and row['level1_diag1'] < 580) or (np.floor(row['level1_diag1']) == 787):\n        df.loc[index, 'level1_diag1'] = 3\n    elif (np.floor(row['level1_diag1']) == 250):\n        df.loc[index, 'level1_diag1'] = 4\n    elif (row['level1_diag1'] >= 800 and row['level1_diag1'] < 1000):\n        df.loc[index, 'level1_diag1'] = 5\n    elif (row['level1_diag1'] >= 710 and row['level1_diag1'] < 740):\n        df.loc[index, 'level1_diag1'] = 6\n    elif (row['level1_diag1'] >= 580 and row['level1_diag1'] < 630) or (np.floor(row['level1_diag1']) == 788):\n        df.loc[index, 'level1_diag1'] = 7\n    elif (row['level1_diag1'] >= 140 and row['level1_diag1'] < 240):\n        df.loc[index, 'level1_diag1'] = 8\n    else:\n        df.loc[index, 'level1_diag1'] = 0\n        \n    if (row['level1_diag2'] >= 390 and row['level1_diag2'] < 460) or (np.floor(row['level1_diag2']) == 785):\n        df.loc[index, 'level1_diag2'] = 1\n    elif (row['level1_diag2'] >= 460 and row['level1_diag2'] < 520) or (np.floor(row['level1_diag2']) == 786):\n        df.loc[index, 'level1_diag2'] = 2\n    elif (row['level1_diag2'] >= 520 and row['level1_diag2'] < 580) or (np.floor(row['level1_diag2']) == 787):\n        df.loc[index, 'level1_diag2'] = 3\n    elif (np.floor(row['level1_diag2']) == 250):\n        df.loc[index, 'level1_diag2'] = 4\n    elif (row['level1_diag2'] >= 800 and row['level1_diag2'] < 1000):\n        df.loc[index, 'level1_diag2'] = 5\n    elif (row['level1_diag2'] >= 710 and row['level1_diag2'] < 740):\n        df.loc[index, 'level1_diag2'] = 6\n    elif (row['level1_diag2'] >= 580 and row['level1_diag2'] < 630) or (np.floor(row['level1_diag2']) == 788):\n        df.loc[index, 'level1_diag2'] = 7\n    elif (row['level1_diag2'] >= 140 and row['level1_diag2'] < 240):\n        df.loc[index, 'level1_diag2'] = 8\n    else:\n        df.loc[index, 'level1_diag2'] = 0\n    \n    if (row['level1_diag3'] >= 390 and row['level1_diag3'] < 460) or (np.floor(row['level1_diag3']) == 785):\n        df.loc[index, 'level1_diag3'] = 1\n    elif (row['level1_diag3'] >= 460 and row['level1_diag3'] < 520) or (np.floor(row['level1_diag3']) == 786):\n        df.loc[index, 'level1_diag3'] = 2\n    elif (row['level1_diag3'] >= 520 and row['level1_diag3'] < 580) or (np.floor(row['level1_diag3']) == 787):\n        df.loc[index, 'level1_diag3'] = 3\n    elif (np.floor(row['level1_diag3']) == 250):\n        df.loc[index, 'level1_diag3'] = 4\n    elif (row['level1_diag3'] >= 800 and row['level1_diag3'] < 1000):\n        df.loc[index, 'level1_diag3'] = 5\n    elif (row['level1_diag3'] >= 710 and row['level1_diag3'] < 740):\n        df.loc[index, 'level1_diag3'] = 6\n    elif (row['level1_diag3'] >= 580 and row['level1_diag3'] < 630) or (np.floor(row['level1_diag3']) == 788):\n        df.loc[index, 'level1_diag3'] = 7\n    elif (row['level1_diag3'] >= 140 and row['level1_diag3'] < 240):\n        df.loc[index, 'level1_diag3'] = 8\n    else:\n        df.loc[index, 'level1_diag3'] = 0\n","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"for index, row in df.iterrows():\n    if (row['level2_diag1'] >= 390 and row['level2_diag1'] < 399):\n        df.loc[index, 'level2_diag1'] = 1\n    elif (row['level2_diag1'] >= 401 and row['level2_diag1'] < 415):\n        df.loc[index, 'level2_diag1'] = 2\n    elif (row['level2_diag1'] >= 415 and row['level2_diag1'] < 460):\n        df.loc[index, 'level2_diag1'] = 3\n    elif (np.floor(row['level2_diag1']) == 785):\n        df.loc[index, 'level2_diag1'] = 4\n    elif (row['level2_diag1'] >= 460 and row['level2_diag1'] < 489):\n        df.loc[index, 'level2_diag1'] = 5\n    elif (row['level2_diag1'] >= 490 and row['level2_diag1'] < 497):\n        df.loc[index, 'level2_diag1'] = 6\n    elif (row['level2_diag1'] >= 500 and row['level2_diag1'] < 520):\n        df.loc[index, 'level2_diag1'] = 7\n    elif (np.floor(row['level2_diag1']) == 786):\n        df.loc[index, 'level2_diag1'] = 8\n    elif (row['level2_diag1'] >= 520 and row['level2_diag1'] < 530):\n        df.loc[index, 'level2_diag1'] = 9\n    elif (row['level2_diag1'] >= 530 and row['level2_diag1'] < 544):\n        df.loc[index, 'level2_diag1'] = 10\n    elif (row['level2_diag1'] >= 550 and row['level2_diag1'] < 554):\n        df.loc[index, 'level2_diag1'] = 11\n    elif (row['level2_diag1'] >= 555 and row['level2_diag1'] < 580):\n        df.loc[index, 'level2_diag1'] = 12\n    elif (np.floor(row['level2_diag1']) == 787):\n        df.loc[index, 'level2_diag1'] = 13\n    elif (np.floor(row['level2_diag1']) == 250):\n        df.loc[index, 'level2_diag1'] = 14\n    elif (row['level2_diag1'] >= 800 and row['level2_diag1'] < 1000):\n        df.loc[index, 'level2_diag1'] = 15\n    elif (row['level2_diag1'] >= 710 and row['level2_diag1'] < 740):\n        df.loc[index, 'level2_diag1'] = 16\n    elif (row['level2_diag1'] >= 580 and row['level2_diag1'] < 630):\n        df.loc[index, 'level2_diag1'] = 17\n    elif (np.floor(row['level2_diag1']) == 788):\n        df.loc[index, 'level2_diag1'] = 18\n    elif (row['level2_diag1'] >= 140 and row['level2_diag1'] < 240):\n        df.loc[index, 'level2_diag1'] = 19\n    elif row['level2_diag1'] >= 240 and row['level2_diag1'] < 280 and (np.floor(row['level2_diag1']) != 250):\n        df.loc[index, 'level2_diag1'] = 20\n    elif (row['level2_diag1'] >= 680 and row['level2_diag1'] < 710) or (np.floor(row['level2_diag1']) == 782):\n        df.loc[index, 'level2_diag1'] = 21\n    elif (row['level2_diag1'] >= 290 and row['level2_diag1'] < 320):\n        df.loc[index, 'level2_diag1'] = 22\n    else:\n        df.loc[index, 'level2_diag1'] = 0\n        \n    if (row['level2_diag2'] >= 390 and row['level2_diag2'] < 399):\n        df.loc[index, 'level2_diag2'] = 1\n    elif (row['level2_diag2'] >= 401 and row['level2_diag2'] < 415):\n        df.loc[index, 'level2_diag2'] = 2\n    elif (row['level2_diag2'] >= 415 and row['level2_diag2'] < 460):\n        df.loc[index, 'level2_diag2'] = 3\n    elif (np.floor(row['level2_diag2']) == 785):\n        df.loc[index, 'level2_diag2'] = 4\n    elif (row['level2_diag2'] >= 460 and row['level2_diag2'] < 489):\n        df.loc[index, 'level2_diag2'] = 5\n    elif (row['level2_diag2'] >= 490 and row['level2_diag2'] < 497):\n        df.loc[index, 'level2_diag2'] = 6\n    elif (row['level2_diag2'] >= 500 and row['level2_diag2'] < 520):\n        df.loc[index, 'level2_diag2'] = 7\n    elif (np.floor(row['level2_diag2']) == 786):\n        df.loc[index, 'level2_diag2'] = 8\n    elif (row['level2_diag2'] >= 520 and row['level2_diag2'] < 530):\n        df.loc[index, 'level2_diag2'] = 9\n    elif (row['level2_diag2'] >= 530 and row['level2_diag2'] < 544):\n        df.loc[index, 'level2_diag2'] = 10\n    elif (row['level2_diag2'] >= 550 and row['level2_diag2'] < 554):\n        df.loc[index, 'level2_diag2'] = 11\n    elif (row['level2_diag2'] >= 555 and row['level2_diag2'] < 580):\n        df.loc[index, 'level2_diag2'] = 12\n    elif (np.floor(row['level2_diag2']) == 787):\n        df.loc[index, 'level2_diag2'] = 13\n    elif (np.floor(row['level2_diag2']) == 250):\n        df.loc[index, 'level2_diag2'] = 14\n    elif (row['level2_diag2'] >= 800 and row['level2_diag2'] < 1000):\n        df.loc[index, 'level2_diag2'] = 15\n    elif (row['level2_diag2'] >= 710 and row['level2_diag2'] < 740):\n        df.loc[index, 'level2_diag2'] = 16\n    elif (row['level2_diag2'] >= 580 and row['level2_diag2'] < 630):\n        df.loc[index, 'level2_diag2'] = 17\n    elif (np.floor(row['level2_diag2']) == 788):\n        df.loc[index, 'level2_diag2'] = 18\n    elif (row['level2_diag2'] >= 140 and row['level2_diag2'] < 240):\n        df.loc[index, 'level2_diag2'] = 19\n    elif row['level2_diag2'] >= 240 and row['level2_diag2'] < 280 and (np.floor(row['level2_diag2']) != 250):\n        df.loc[index, 'level2_diag2'] = 20\n    elif (row['level2_diag2'] >= 680 and row['level2_diag2'] < 710) or (np.floor(row['level2_diag2']) == 782):\n        df.loc[index, 'level2_diag2'] = 21\n    elif (row['level2_diag2'] >= 290 and row['level2_diag2'] < 320):\n        df.loc[index, 'level2_diag2'] = 22\n    else:\n        df.loc[index, 'level2_diag2'] = 0\n        \n        \n    if (row['level2_diag3'] >= 390 and row['level2_diag3'] < 399):\n        df.loc[index, 'level2_diag3'] = 1\n    elif (row['level2_diag3'] >= 401 and row['level2_diag3'] < 415):\n        df.loc[index, 'level2_diag3'] = 2\n    elif (row['level2_diag3'] >= 415 and row['level2_diag3'] < 460):\n        df.loc[index, 'level2_diag3'] = 3\n    elif (np.floor(row['level2_diag3']) == 785):\n        df.loc[index, 'level2_diag3'] = 4\n    elif (row['level2_diag3'] >= 460 and row['level2_diag3'] < 489):\n        df.loc[index, 'level2_diag3'] = 5\n    elif (row['level2_diag3'] >= 490 and row['level2_diag3'] < 497):\n        df.loc[index, 'level2_diag3'] = 6\n    elif (row['level2_diag3'] >= 500 and row['level2_diag3'] < 520):\n        df.loc[index, 'level2_diag3'] = 7\n    elif (np.floor(row['level2_diag3']) == 786):\n        df.loc[index, 'level2_diag3'] = 8\n    elif (row['level2_diag3'] >= 520 and row['level2_diag3'] < 530):\n        df.loc[index, 'level2_diag3'] = 9\n    elif (row['level2_diag3'] >= 530 and row['level2_diag3'] < 544):\n        df.loc[index, 'level2_diag3'] = 10\n    elif (row['level2_diag3'] >= 550 and row['level2_diag3'] < 554):\n        df.loc[index, 'level2_diag3'] = 11\n    elif (row['level2_diag3'] >= 555 and row['level2_diag3'] < 580):\n        df.loc[index, 'level2_diag3'] = 12\n    elif (np.floor(row['level2_diag3']) == 787):\n        df.loc[index, 'level2_diag3'] = 13\n    elif (np.floor(row['level2_diag3']) == 250):\n        df.loc[index, 'level2_diag3'] = 14\n    elif (row['level2_diag3'] >= 800 and row['level2_diag3'] < 1000):\n        df.loc[index, 'level2_diag3'] = 15\n    elif (row['level2_diag3'] >= 710 and row['level2_diag3'] < 740):\n        df.loc[index, 'level2_diag3'] = 16\n    elif (row['level2_diag3'] >= 580 and row['level2_diag3'] < 630):\n        df.loc[index, 'level2_diag3'] = 17\n    elif (np.floor(row['level2_diag3']) == 788):\n        df.loc[index, 'level2_diag3'] = 18\n    elif (row['level2_diag3'] >= 140 and row['level2_diag3'] < 240):\n        df.loc[index, 'level2_diag3'] = 19\n    elif row['level2_diag3'] >= 240 and row['level2_diag3'] < 280 and (np.floor(row['level2_diag3']) != 250):\n        df.loc[index, 'level2_diag3'] = 20\n    elif (row['level2_diag3'] >= 680 and row['level2_diag3'] < 710) or (np.floor(row['level2_diag3']) == 782):\n        df.loc[index, 'level2_diag3'] = 21\n    elif (row['level2_diag3'] >= 290 and row['level2_diag3'] < 320):\n        df.loc[index, 'level2_diag3'] = 22\n    else:\n        df.loc[index, 'level2_diag3'] = 0","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization","metadata":{}},{"cell_type":"markdown","source":"#### Distribution of Readmission\nOur target variable is imbalance. Number of readmitted patient are quite less as compared to Not readmitted","metadata":{}},{"cell_type":"code","source":"# Distribution of Readmission \nsns.countplot(df['readmitted']).set_title('Distrinution of Readmission')","metadata":{"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"#### Time in Hospital and Readmission\n","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(13,7),)\nax=sns.kdeplot(df.loc[(df['readmitted'] == 0),'time_in_hospital'] , color='b',shade=True,label='Not Readmitted')\nax=sns.kdeplot(df.loc[(df['readmitted'] == 1),'time_in_hospital'] , color='r',shade=True, label='Readmitted')\nax.set(xlabel='Time in Hospital', ylabel='Frequency')\nplt.title('Time in Hospital VS. Readmission')","metadata":{"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"#### Age and Readmission","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nsns.countplot(y= df['age'], hue = df['readmitted']).set_title('Age of Patient VS. Readmission')","metadata":{"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"#### Ethnicity of patient and Readmission","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(y = df['race'], hue = df['readmitted'])","metadata":{"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"#### Number of medication used and Readmission","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.barplot(x = df['readmitted'], y = df['num_medications']).set_title(\"Number of medication used VS. Readmission\")","metadata":{"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"#### Gender and Readmission\n* Male = 1\n* Female = 0","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(df['gender'], hue = df['readmitted']).set_title(\"Gender of Patient VS. Readmission\")","metadata":{"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"#### Change of Medication and Readmission\n* Change = 1\n* No Change = 0","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(df['change'], hue = df['readmitted']).set_title('Change of Medication VS. Readmission')","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"#### Diabetes Medication prescribed and Readmission\n* Diabetes Medication - medications Nominal Indicates if there was any diabetic medication prescribed.\n* Values: “yes” : 1 “no” : 0","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(df['diabetesMed'], hue = df['readmitted']).set_title('Diabetes Medication prescribed VS Readmission')","metadata":{"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"#### Service Utilization and Readmission\n","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.barplot( y = df['service_utilization'], x = df['readmitted']).set_title('Service Utilization VS. Readmission')","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"#### Glucose serum test result and Readmission\n*Glucose Serum test* - A blood glucose test is used to find out if your blood sugar levels are in the healthy range. It is often used to help diagnose and monitor diabetes.\n\n* '>200' : 1 = indicates diabetes\n* '>300' : 1 = Indicates diabetes\n* 'Norm' : 0 = Normal\n* 'None' : -99 = test was not taken","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(y = df['max_glu_serum'], hue = df['readmitted']).set_title('Glucose test serum test result VS. Readmission')","metadata":{"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"A1C result and Readmission\n*A1C test* - The A1C test is a blood test that provides information about your average levels of blood glucose, also called blood sugar, over the past 3 months.\n*  '>7'   :  1   \n*  '>8'   :  1   \n*    Norm :  0  = Normal \n*    None : -99 = Test was not taken","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(y= df['A1Cresult'], hue = df['readmitted']).set_title('A1C test result VS. Readmission')","metadata":{"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"#### Number of lab procedure and Readmission","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,6),)\nax=sns.kdeplot(df.loc[(df['readmitted'] == 0),'num_lab_procedures'] , color='b',shade=True,label='Not readmitted')\nax=sns.kdeplot(df.loc[(df['readmitted'] == 1),'num_lab_procedures'] , color='r',shade=True, label='readmitted')\nax.set(xlabel='Number of lab procedure', ylabel='Frequency')\nplt.title('Number of lab procedure VS. Readmission')","metadata":{"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Pre-Modeling Data Preprocessing\nThis code converts age as categorical variable to a continuous approximation by assuming mid-point of each age-category as the actual age value. This is done to avoid having to deal with age as a dummy variable in the models which makes interpretation very cumbersome. Also, since age category is not purely nominal but ordinal, we do not want to lose that information by treating it as a simple categorical variable","metadata":{}},{"cell_type":"code","source":"df['age'] = df['age'].astype('int64')\nprint(df.age.value_counts())\n# convert age categories to mid-point values\nage_dict = {1:5, 2:15, 3:25, 4:35, 5:45, 6:55, 7:65, 8:75, 9:85, 10:95}\ndf['age'] = df.age.map(age_dict)\nprint(df.age.value_counts())","metadata":{"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# convert data type of nominal features in dataframe to 'object' type\ni = ['encounter_id', 'patient_nbr', 'gender', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\\\n          'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \\\n          'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose','miglitol', \\\n          'troglitazone', 'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin', \\\n          'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed', \\\n          'age', 'A1Cresult', 'max_glu_serum', 'level1_diag1', 'level1_diag2', 'level1_diag3', 'level2_diag1', 'level2_diag2', 'level2_diag3']\n\ndf[i] = df[i].astype('object')","metadata":{"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"* Number of medication used: Another possibly related factor could be the total number of medications used by the patient (which may indicate severity of their condition and/or the intensity of care). So we created another feature by counting the medications used during the encounter (keys variable in code below is continued from above):","metadata":{}},{"cell_type":"code","source":"df['nummed'] = 0\n\nfor col in keys:\n    df['nummed'] = df['nummed'] + df[col]\ndf['nummed'].value_counts()","metadata":{"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# get list of only numeric features\nnum_col = list(set(list(df._get_numeric_data().columns))- {'readmitted'})\nnum_col","metadata":{"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Removing skewnewss and kurtosis using log transformation if it is above a threshold value -  2\n\nstatdataframe = pd.DataFrame()\nstatdataframe['numeric_column'] = num_col\nskew_before = []\nskew_after = []\n\nkurt_before = []\nkurt_after = []\n\nstandard_deviation_before = []\nstandard_deviation_after = []\n\nlog_transform_needed = []\n\nlog_type = []\n\nfor i in num_col:\n    skewval = df[i].skew()\n    skew_before.append(skewval)\n    \n    kurtval = df[i].kurtosis()\n    kurt_before.append(kurtval)\n    \n    sdval = df[i].std()\n    standard_deviation_before.append(sdval)\n    \n    if (abs(skewval) >2) & (abs(kurtval) >2):\n        log_transform_needed.append('Yes')\n        \n        if len(df[df[i] == 0])/len(df) <=0.02:\n            log_type.append('log')\n            skewvalnew = np.log(pd.DataFrame(df[train_data[i] > 0])[i]).skew()\n            skew_after.append(skewvalnew)\n            \n            kurtvalnew = np.log(pd.DataFrame(df[train_data[i] > 0])[i]).kurtosis()\n            kurt_after.append(kurtvalnew)\n            \n            sdvalnew = np.log(pd.DataFrame(df[train_data[i] > 0])[i]).std()\n            standard_deviation_after.append(sdvalnew)\n            \n        else:\n            log_type.append('log1p')\n            skewvalnew = np.log1p(pd.DataFrame(df[df[i] >= 0])[i]).skew()\n            skew_after.append(skewvalnew)\n        \n            kurtvalnew = np.log1p(pd.DataFrame(df[df[i] >= 0])[i]).kurtosis()\n            kurt_after.append(kurtvalnew)\n            \n            sdvalnew = np.log1p(pd.DataFrame(df[df[i] >= 0])[i]).std()\n            standard_deviation_after.append(sdvalnew)\n            \n    else:\n        log_type.append('NA')\n        log_transform_needed.append('No')\n        \n        skew_after.append(skewval)\n        kurt_after.append(kurtval)\n        standard_deviation_after.append(sdval)\n\nstatdataframe['skew_before'] = skew_before\nstatdataframe['kurtosis_before'] = kurt_before\nstatdataframe['standard_deviation_before'] = standard_deviation_before\nstatdataframe['log_transform_needed'] = log_transform_needed\nstatdataframe['log_type'] = log_type\nstatdataframe['skew_after'] = skew_after\nstatdataframe['kurtosis_after'] = kurt_after\nstatdataframe['standard_deviation_after'] = standard_deviation_after","metadata":{"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"statdataframe","metadata":{"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# performing the log transformation for the columns determined to be needing it above.\n\nfor i in range(len(statdataframe)):\n    if statdataframe['log_transform_needed'][i] == 'Yes':\n        colname = str(statdataframe['numeric_column'][i])\n        \n        if statdataframe['log_type'][i] == 'log':\n            df = df[df[colname] > 0]\n            df[colname + \"_log\"] = np.log(df[colname])\n            \n        elif statdataframe['log_type'][i] == 'log1p':\n            df = df[df[colname] >= 0]\n            df[colname + \"_log1p\"] = np.log1p(df[colname])","metadata":{"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['number_outpatient', 'number_inpatient', 'number_emergency','service_utilization'], axis = 1)","metadata":{"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# get list of only numeric features\nnumerics = list(set(list(df._get_numeric_data().columns))- {'readmitted'})\nnumerics","metadata":{"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# show list of features that are categorical\ndf.encounter_id = df.encounter_id.astype('int64')\ndf.patient_nbr = df.patient_nbr.astype('int64')\ndf.diabetesMed = df.diabetesMed.astype('int64')\ndf.change = df.change.astype('int64')\n\n# convert data type of nominal features in dataframe to 'object' type for aggregating\ni = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \\\n          'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose','miglitol', \\\n          'troglitazone', 'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin', \\\n          'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone','A1Cresult']\ndf[i] = df[i].astype('int64')\n\ndf.dtypes","metadata":{"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"dfcopy = df.copy(deep = True)","metadata":{"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"df['readmitted'] = df['readmitted'].apply(lambda x: 0 if x == 2 else x)","metadata":{"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# drop individual diagnosis columns that have too granular disease information\n# also drop level 2 categorization (which was not comparable with any reference)\n# also drop level 1 secondary and tertiary diagnoses\ndf.drop(['diag_1', 'diag_2', 'diag_3', 'level2_diag1', 'level1_diag2', 'level2_diag2', 'level1_diag3',\n         'level2_diag3'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"interactionterms = [('num_medications','time_in_hospital'),\n('num_medications','num_procedures'),\n('time_in_hospital','num_lab_procedures'),\n('num_medications','num_lab_procedures'),\n('num_medications','number_diagnoses'),\n('age','number_diagnoses'),\n('change','num_medications'),\n('number_diagnoses','time_in_hospital'),\n('num_medications','numchange')]","metadata":{"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"for inter in interactionterms:\n    name = inter[0] + '|' + inter[1]\n    df[name] = df[inter[0]] * df[inter[1]]","metadata":{"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"df[['num_medications','time_in_hospital', 'num_medications|time_in_hospital']].head()","metadata":{"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# Feature Scaling\ndatf = pd.DataFrame()\ndatf['features'] = numerics\ndatf['std_dev'] = datf['features'].apply(lambda x: df[x].std())\ndatf['mean'] = datf['features'].apply(lambda x: df[x].mean())","metadata":{"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# dropping multiple encounters while keeping either first or last encounter of these patients\ndf2 = df.drop_duplicates(subset= ['patient_nbr'], keep = 'first')\ndf2.shape","metadata":{"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# standardize function\ndef standardize(raw_data):\n    return ((raw_data - np.mean(raw_data, axis = 0)) / np.std(raw_data, axis = 0))","metadata":{"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"df2[numerics] = standardize(df2[numerics])\nimport scipy as sp\ndf2 = df2[(np.abs(sp.stats.zscore(df2[numerics])) < 3).all(axis=1)]","metadata":{"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"from matplotlib.colors import ListedColormap\nmy_cmap = ListedColormap(sns.light_palette((250, 100, 50), input=\"husl\", n_colors=50).as_hex())\ntable = df2.drop(['patient_nbr', 'encounter_id'], axis=1).corr(method='pearson')\ntable.style.background_gradient(cmap=my_cmap, axis = 0)","metadata":{"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"df2['level1_diag1'] = df2['level1_diag1'].astype('object')\ndf_pd = pd.get_dummies(df2, columns=['gender', 'admission_type_id', 'discharge_disposition_id',\n                                      'admission_source_id', 'max_glu_serum', 'A1Cresult', 'level1_diag1'], drop_first = True)\njust_dummies = pd.get_dummies(df_pd['race'])\ndf_pd = pd.concat([df_pd, just_dummies], axis=1)      \ndf_pd.drop(['race'], inplace=True, axis=1)","metadata":{"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"non_num_cols = ['race', 'gender', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', \n                'max_glu_serum', 'A1Cresult', 'level1_diag1' ]","metadata":{"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"num_cols = list(set(list(df._get_numeric_data().columns))- {'readmitted', 'change'})\nnum_cols","metadata":{"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"new_non_num_cols = []\nfor i in non_num_cols:\n    for j in df_pd.columns:\n        if i in j:\n            new_non_num_cols.append(j)","metadata":{"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"new_non_num_cols","metadata":{"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"l = []\nfor feature in list(df_pd.columns):\n    if '|' in feature:\n        l.append(feature)\nl","metadata":{"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"df_pd.head().T","metadata":{"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"feature_set = ['age', 'time_in_hospital', 'num_procedures', 'num_medications', 'number_outpatient_log1p', \n                 'number_emergency_log1p', 'number_inpatient_log1p', 'number_diagnoses', 'metformin', \n                 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n                 'pioglitazone', 'rosiglitazone', 'acarbose', 'tolazamide', 'insulin', 'glyburide-metformin',\n                 'AfricanAmerican', 'Asian', 'Caucasian', 'Hispanic', 'Other', 'gender_1', \n                 'admission_type_id_3', 'admission_type_id_5', 'discharge_disposition_id_2', 'discharge_disposition_id_7', \n                 'discharge_disposition_id_10', 'discharge_disposition_id_18', 'admission_source_id_4',\n                 'admission_source_id_7', 'admission_source_id_9', 'max_glu_serum_0', 'max_glu_serum_1', 'A1Cresult_0',\n                 'A1Cresult_1', 'num_medications|time_in_hospital', 'num_medications|num_procedures',\n                 'time_in_hospital|num_lab_procedures', 'num_medications|num_lab_procedures', 'num_medications|number_diagnoses',\n                 'age|number_diagnoses', 'change|num_medications', 'number_diagnoses|time_in_hospital',\n                 'num_medications|numchange', 'level1_diag1_1.0', 'level1_diag1_2.0', 'level1_diag1_3.0', 'level1_diag1_4.0',\n                 'level1_diag1_5.0','level1_diag1_6.0', 'level1_diag1_7.0', 'level1_diag1_8.0']","metadata":{"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"X = df_pd[feature_set]\ny = df_pd['readmitted']","metadata":{"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"df_pd['readmitted'].value_counts()","metadata":{"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\nlogit = LogisticRegression(fit_intercept=True, penalty='l1')\nlogit.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"logit_pred = logit.predict(X_test)\npd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(logit_pred, name = 'Predict'), margins = True)","metadata":{"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score\nprint(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, logit_pred)))\nprint(\"Precision is {0:.2f}\".format(precision_score(y_test, logit_pred)))\nprint(\"Recall is {0:.2f}\".format(recall_score(y_test, logit_pred)))","metadata":{"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"Since our target variable is having class imbalance problem, So will use SMOTE technique to resolve it\n","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom collections import Counter\nprint('Original dataset shape {}'.format(Counter(y_train)))\nsm = SMOTE(random_state=20)\ntrain_input_new, train_output_new = sm.fit_sample(X_train, y_train)\nprint('New dataset shape {}'.format(Counter(train_output_new)))","metadata":{"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"train_input_new = pd.DataFrame(train_input_new, columns = list(X.columns))\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nX_train, X_test, y_train, y_test = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\nlogit = LogisticRegression(fit_intercept=True, penalty='l1')\nlogit.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"logit_pred = logit.predict(X_test)\npd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(logit_pred, name = 'Predict'), margins = True)","metadata":{"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, logit_pred)))\nprint(\"Precision is {0:.2f}\".format(precision_score(y_test, logit_pred)))\nprint(\"Recall is {0:.2f}\".format(recall_score(y_test, logit_pred)))\n\naccuracy_logit = accuracy_score(y_test, logit_pred)\nprecision_logit = precision_score(y_test, logit_pred)\nrecall_logit = recall_score(y_test, logit_pred)","metadata":{"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree","metadata":{}},{"cell_type":"code","source":"feature_set_no_int = ['age', 'time_in_hospital', 'num_procedures', 'num_medications', 'number_outpatient_log1p', \n                 'number_emergency_log1p', 'number_inpatient_log1p', 'number_diagnoses', 'metformin', \n                 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', \n                 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose', \n                 'tolazamide', 'insulin', 'glyburide-metformin',\n                 'AfricanAmerican', 'Asian', 'Caucasian', \n                 'Hispanic', 'Other', 'gender_1', \n                 'admission_type_id_3', 'admission_type_id_5', \n                 'discharge_disposition_id_2', 'discharge_disposition_id_7', \n                 'discharge_disposition_id_10', 'discharge_disposition_id_18', \n                 'admission_source_id_4', 'admission_source_id_7', \n                 'admission_source_id_9', 'max_glu_serum_0', \n                 'max_glu_serum_1', 'A1Cresult_0', 'A1Cresult_1', \n                 'level1_diag1_1.0',\n                 'level1_diag1_2.0',\n                 'level1_diag1_3.0',\n                 'level1_diag1_4.0',\n                 'level1_diag1_5.0',\n                 'level1_diag1_6.0',\n                 'level1_diag1_7.0',\n                 'level1_diag1_8.0']","metadata":{"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"X = df_pd[feature_set_no_int]\ny = df_pd['readmitted']\ndf_pd['readmitted'].value_counts()","metadata":{"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"print('Original dataset shape {}'.format(Counter(y)))\nsmt = SMOTE(random_state=20)\ntrain_input_new, train_output_new = smt.fit_sample(X, y)\nprint('New dataset shape {}'.format(Counter(train_output_new)))\ntrain_input_new = pd.DataFrame(train_input_new, columns = list(X.columns))\nX_train, X_test, y_train, y_test = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)","metadata":{"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=10)\ndtree.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"dtree_pred = dtree.predict(X_test)\npd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(dtree_pred, name = 'Predict'), margins = True)","metadata":{"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, dtree_pred)))\nprint(\"Precision is {0:.2f}\".format(precision_score(y_test, dtree_pred)))\nprint(\"Recall is {0:.2f}\".format(recall_score(y_test, dtree_pred)))\n\naccuracy_dtree = accuracy_score(y_test, dtree_pred)\nprecision_dtree = precision_score(y_test, dtree_pred)\nrecall_dtree = recall_score(y_test, dtree_pred)","metadata":{"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# Create list of top most features based on importance\nfeature_names = X_train.columns\nfeature_imports = dtree.feature_importances_\nmost_imp_features = pd.DataFrame([f for f in zip(feature_names,feature_imports)], columns=[\"Feature\", \"Importance\"]).nlargest(10, \"Importance\")\nmost_imp_features.sort_values(by=\"Importance\", inplace=True)\nprint(most_imp_features)\nplt.figure(figsize=(10,6))\nplt.barh(range(len(most_imp_features)), most_imp_features.Importance, align='center', alpha=0.8)\nplt.yticks(range(len(most_imp_features)), most_imp_features.Feature, fontsize=14)\nplt.xlabel('Importance')\nplt.title('Most important features - Decision Tree')\nplt.show()","metadata":{"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"X = df_pd[feature_set_no_int]\ny = df_pd['readmitted']\n\nprint('Original dataset shape {}'.format(Counter(y)))\nsmt = SMOTE(random_state=20)\ntrain_input_new, train_output_new = smt.fit_sample(X, y)\nprint('New dataset shape {}'.format(Counter(train_output_new)))\ntrain_input_new = pd.DataFrame(train_input_new, columns = list(X.columns))\nX_train, X_test, y_train, y_test = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)","metadata":{"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrm = RandomForestClassifier(n_estimators = 10, max_depth=25, criterion = \"gini\", min_samples_split=10)\nrm.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"rm_prd = rm.predict(X_test)\npd.crosstab(pd.Series(y_test, name = 'Actual'), pd.Series(rm_prd, name = 'Predict'), margins = True)","metadata":{"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, rm_prd)))\nprint(\"Precision is {0:.2f}\".format(precision_score(y_test, rm_prd)))\nprint(\"Recall is {0:.2f}\".format(recall_score(y_test, rm_prd)))\n\naccuracy_rm = accuracy_score(y_test, rm_prd)\nprecision_rm = precision_score(y_test, rm_prd)\nrecall_rm = recall_score(y_test, rm_prd)","metadata":{"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# Create list of top most features based on importance\nfeature_names = X_train.columns\nfeature_imports = rm.feature_importances_\nmost_imp_features = pd.DataFrame([f for f in zip(feature_names,feature_imports)], columns=[\"Feature\", \"Importance\"]).nlargest(10, \"Importance\")\nmost_imp_features.sort_values(by=\"Importance\", inplace=True)\nplt.figure(figsize=(10,6))\nplt.barh(range(len(most_imp_features)), most_imp_features.Importance, align='center', alpha=0.8)\nplt.yticks(range(len(most_imp_features)), most_imp_features.Feature, fontsize=14)\nplt.xlabel('Importance')\nplt.title('Most important features - Random Forest ')\nplt.show()","metadata":{"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"## Model Comparision","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 7))\nax = plt.subplot(111)\n\nmodels = ['Logistic Regression', 'Decision Tree', 'Random Forests']\nvalues = [accuracy_logit, accuracy_dtree, accuracy_rm]\nmodel = np.arange(len(models))\n\nplt.bar(model, values, align='center', width = 0.15, alpha=0.7, color = 'red', label= 'accuracy')\nplt.xticks(model, models)\n           \n\n           \nax = plt.subplot(111)\n\nmodels = ['Logistic Regression', 'Decision Tree', 'Random Forests']\nvalues = [precision_logit, precision_dtree, precision_rm]\nmodel = np.arange(len(models))\n\nplt.bar(model+0.15, values, align='center', width = 0.15, alpha=0.7, color = 'blue', label = 'precision')\nplt.xticks(model, models)\n\n\n\nax = plt.subplot(111)\n\nmodels = ['Logistic Regression', 'Decision Tree', 'Random Forests' ]\nvalues = [recall_logit, recall_dtree, recall_rm, ]\nmodel = np.arange(len(models))\n\nplt.bar(model+0.3, values, align='center', width = 0.15, alpha=0.7, color = 'green', label = 'recall')\nplt.xticks(model, models)\n\n\n\nplt.ylabel('Performance Metrics for Different models')\nplt.title('Model')\n    \n# removing the axis on the top and right of the plot window\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.legend()\n\nplt.show()           ","metadata":{"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}